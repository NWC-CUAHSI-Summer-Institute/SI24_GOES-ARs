{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a786a244-1419-482f-806e-38352d8650a6",
   "metadata": {},
   "source": [
    "# GOES historical data download with respect to labeled AR data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6596b-2a95-49d0-b16b-019172055df6",
   "metadata": {},
   "source": [
    "First, load the labeled_AR data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddfb7bc-ff9e-45ac-8675-981cf9aac30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeled_AR/data-1996-06-09-01-1_0.nc',\n",
       " 'labeled_AR/data-1996-07-11-01-1_0.nc',\n",
       " 'labeled_AR/data-1996-07-18-01-1_0.nc',\n",
       " 'labeled_AR/data-1996-07-18-01-1_1.nc',\n",
       " 'labeled_AR/data-1996-07-18-01-1_2.nc',\n",
       " 'labeled_AR/data-1996-09-01-01-1_0.nc',\n",
       " 'labeled_AR/data-1996-09-01-01-1_1.nc',\n",
       " 'labeled_AR/data-1996-09-12-01-1_0.nc',\n",
       " 'labeled_AR/data-1996-09-26-01-1_0.nc',\n",
       " 'labeled_AR/data-1996-09-26-01-1_1.nc',\n",
       " 'labeled_AR/data-1996-10-03-01-1_0.nc',\n",
       " 'labeled_AR/data-1996-10-03-01-1_1.nc',\n",
       " 'labeled_AR/data-1997-06-01-01-1_0.nc',\n",
       " 'labeled_AR/data-1997-06-02-01-1_0.nc',\n",
       " 'labeled_AR/data-1997-06-05-01-1_0.nc',\n",
       " 'labeled_AR/data-1997-06-18-01-1_0.nc',\n",
       " 'labeled_AR/data-1997-07-09-01-1_0.nc',\n",
       " 'labeled_AR/data-1997-07-09-01-1_1.nc',\n",
       " 'labeled_AR/data-1997-08-14-01-1_0.nc',\n",
       " 'labeled_AR/data-1997-08-14-01-1_1.nc',\n",
       " 'labeled_AR/data-1997-08-14-01-1_2.nc',\n",
       " 'labeled_AR/data-1997-08-14-01-1_3.nc',\n",
       " 'labeled_AR/data-1997-08-29-01-1_0.nc',\n",
       " 'labeled_AR/data-1997-10-12-01-1_0.nc',\n",
       " 'labeled_AR/data-1997-10-12-01-1_1.nc',\n",
       " 'labeled_AR/data-1997-10-12-01-1_2.nc',\n",
       " 'labeled_AR/data-1997-10-14-01-1_0.nc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory where files are stored\n",
    "download_dir = 'labeled_AR'\n",
    "\n",
    "# List to store file names\n",
    "files = []\n",
    "\n",
    "# Iterate over files in the directory\n",
    "for file_name in os.listdir(download_dir):\n",
    "    if file_name.endswith('.nc'):\n",
    "        files.append(os.path.join(download_dir, file_name))\n",
    "\n",
    "# Sort the list of file names\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d60538cb-c328-4ab8-ad32-5c1b0d93ce08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Directory to save the downloaded files\u001b[39;00m\n\u001b[1;32m      7\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Base URL\u001b[39;00m\n\u001b[1;32m     11\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.ncei.noaa.gov/data/gridsat-goes/access/goes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Directory to save the downloaded files\n",
    "save_dir = \"\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://www.ncei.noaa.gov/data/gridsat-goes/access/goes\"\n",
    "\n",
    "# Specify start and end dates\n",
    "start_date = datetime(1996, 9, 26, 0, 0)\n",
    "end_date = datetime(1996, 10, 5, 23, 0)\n",
    "\n",
    "# Function to generate URLs based on date range\n",
    "def generate_urls(start_date, end_date):\n",
    "    urls = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime(\"%Y.%m.%d.%H00\")\n",
    "        filename = f\"GridSat-GOES.goes08.{date_str}.v01.nc\"\n",
    "        url = f\"{base_url}/{current_date.year}/{current_date.strftime('%m')}/{filename}\"\n",
    "        urls.append(url)\n",
    "        current_date += timedelta(hours=1)\n",
    "    return urls\n",
    "\n",
    "# Function to download a file\n",
    "def download_file(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        filename = os.path.join(save_dir, os.path.basename(url))\n",
    "        with open(filename, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url}\")\n",
    "\n",
    "# Generate the list of URLs to download\n",
    "urls = generate_urls(start_date, end_date)\n",
    "\n",
    "# Use ThreadPoolExecutor to download files concurrently\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(download_file, urls)\n",
    "\n",
    "print(\"All files downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c0e3b9-a9f5-4597-8099-ef79e57c2a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.bash_history',\n",
       " '.ipython',\n",
       " 'shared',\n",
       " 'NWM_CNN_california_AR_2023',\n",
       " 'GOES_historical.ipynb',\n",
       " '.wget-hsts',\n",
       " 'data_science_principals',\n",
       " '.cache',\n",
       " 'labeled_AR',\n",
       " 'reference_CONUS.gpkg',\n",
       " 'geopandas',\n",
       " 'climatenet_data',\n",
       " 'neuralhydrology',\n",
       " 'wget-log',\n",
       " 'SI_fellows_2024_introductions',\n",
       " '.jupyter',\n",
       " 'Untitled4.ipynb',\n",
       " 'GOES_historical',\n",
       " 'Untitled3.ipynb',\n",
       " '.local',\n",
       " 'Untitled1.ipynb',\n",
       " 'Untitled2.ipynb',\n",
       " 'labeled_AR.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.conda',\n",
       " 'hydrofabric',\n",
       " '.jupyter-server-log.txt',\n",
       " '.config',\n",
       " 'CAMELS_data_sample']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(os.getcwd())\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89ad0ad9-b3f8-45fe-b543-321a3b6a8e14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m files \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Iterate over files in the directory\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     12\u001b[0m         files\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_dir, file_name))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory where files are stored\n",
    "download_dir = ''\n",
    "\n",
    "# List to store file names\n",
    "files = []\n",
    "\n",
    "# Iterate over files in the directory\n",
    "for file_name in os.listdir(download_dir):\n",
    "    if file_name.endswith('.nc'):\n",
    "        files.append(os.path.join(download_dir, file_name))\n",
    "\n",
    "# Sort the list of file names\n",
    "files.sort()\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be09eba-723a-4af3-8fc2-e6ed0e490915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cartopy\n",
      "  Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from cartopy) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from cartopy) (3.8.4)\n",
      "Collecting shapely>=1.7 (from cartopy)\n",
      "  Using cached shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: packaging>=20 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from cartopy) (23.2)\n",
      "Collecting pyshp>=2.3 (from cartopy)\n",
      "  Downloading pyshp-2.3.1-py2.py3-none-any.whl.metadata (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m444.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyproj>=3.3.1 (from cartopy)\n",
      "  Using cached pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.5->cartopy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.5->cartopy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.5->cartopy) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.5->cartopy) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.5->cartopy) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.5->cartopy) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.5->cartopy) (2.8.2)\n",
      "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pyproj>=3.3.1->cartopy) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.5->cartopy) (1.16.0)\n",
      "Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Installing collected packages: shapely, pyshp, pyproj, cartopy\n",
      "Successfully installed cartopy-0.23.0 pyproj-3.6.1 pyshp-2.3.1 shapely-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d966df94-9dab-4992-b8e4-1a372ec9fd6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# List of NetCDF files to process\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m nc_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Define the latitude and longitude bounds for the US\u001b[39;00m\n\u001b[1;32m     12\u001b[0m lat_bounds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m]  \u001b[38;5;66;03m# Southernmost and northernmost points of the continental US\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "\n",
    "# Directory containing the NetCDF files\n",
    "data_dir = ''\n",
    "# List of NetCDF files to process\n",
    "nc_files = [f for f in os.listdir(data_dir) if f.endswith('.nc')]\n",
    "\n",
    "# Define the latitude and longitude bounds for the US\n",
    "lat_bounds = [10, 100]  # Southernmost and northernmost points of the continental US\n",
    "lon_bounds = [-180, -40]  # Westernmost and easternmost points of the continental US\n",
    "\n",
    "# Function to process and plot data from a single file\n",
    "def process_and_plot(nc_file):\n",
    "    # Open the NetCDF file\n",
    "    dataset = xr.open_dataset(os.path.join(data_dir, nc_file))\n",
    "    \n",
    "    # Select the variable you want to plot\n",
    "    variable = dataset['ch3']\n",
    "    \n",
    "    # Crop the data to the US bounds\n",
    "    variable_us = variable.sel(lat=slice(lat_bounds[0], lat_bounds[1]), lon=slice(lon_bounds[0], lon_bounds[1]))\n",
    "    \n",
    "    # Create a figure and axis with a globe projection\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = plt.axes(projection=ccrs.Mercator())\n",
    "    \n",
    "    # Plot the variable on the globe\n",
    "    variable_us.plot(ax=ax, transform=ccrs.PlateCarree(), cmap='viridis')  # Added cmap for better visualization\n",
    "    \n",
    "    # Add coastlines and gridlines\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    \n",
    "    # Set the title\n",
    "    plt.title(f'Variable from {nc_file} (Cropped to US)')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Iterate through the NetCDF files and process them\n",
    "for nc_file in nc_files:\n",
    "    process_and_plot(nc_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
